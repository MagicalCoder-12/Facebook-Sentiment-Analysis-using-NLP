{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2ca711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 30000 harsh comments and saved to 'harsh_comments.csv'\n",
      "\n",
      "Sample comments:\n",
      "                                       Comment Sentiment\n",
      "0                  Screw this. This is broken.         N\n",
      "1            This site absolute is a disaster.         N\n",
      "2  Shitty as always. This update is a failure.         N\n",
      "3                     This complete is a joke.         N\n",
      "4                       This bloody is a joke.         N\n",
      "5  Shitty as always. This disaster is useless.         N\n",
      "6            Oh, yay. This thing sucks. As if.         N\n",
      "7               Piss off. This crap is broken.         N\n",
      "8            This feature pathetic is a waste.         N\n",
      "9           This update fucking is a disaster.         N\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Base components for generating varied harsh comments\n",
    "subjects = [\n",
    "    \"this\", \"this app\", \"this update\", \"this movie\", \"this game\", \"this service\",\n",
    "    \"this feature\", \"this site\", \"this thing\", \"this product\", \"this crap\",\n",
    "    \"this garbage\", \"this mess\", \"this disaster\", \"this junk\", \"this platform\"\n",
    "]\n",
    "\n",
    "intensifiers = [\n",
    "    \"total\", \"complete\", \"absolute\", \"utter\", \"freaking\", \"damn\", \"fucking\",\n",
    "    \"goddamn\", \"bloody\", \"sheer\", \"pure\", \"stupid\", \"pathetic\", \"lousy\", \"shitty\"\n",
    "]\n",
    "\n",
    "negatives = [\n",
    "    \"sucks\", \"is awful\", \"is terrible\", \"is a disaster\", \"is garbage\", \"is trash\",\n",
    "    \"is a joke\", \"is useless\", \"is broken\", \"is pathetic\", \"is a waste\",\n",
    "    \"is crap\", \"is bullshit\", \"is a failure\", \"is the worst\", \"is shit\"\n",
    "]\n",
    "\n",
    "sarcasm_starters = [\n",
    "    \"Oh, great.\", \"Wow, brilliant.\", \"Nice one.\", \"Oh, fantastic.\", \"Sure, perfect.\",\n",
    "    \"Love this.\", \"So impressive.\", \"What a genius move.\", \"Really top-notch.\",\n",
    "    \"Oh, yay.\", \"I’m thrilled.\", \"How wonderful.\", \"Great job.\", \"So amazing.\"\n",
    "]\n",
    "\n",
    "sarcasm_followups = [\n",
    "    \"Not.\", \"Yeah, right.\", \"As if.\", \"In your dreams.\", \"What a surprise.\",\n",
    "    \"Said no one ever.\", \"Totally worth it.\", \"Couldn’t be better.\",\n",
    "    \"Really nailed it.\", \"Just what I needed.\", \"Can’t get enough.\"\n",
    "]\n",
    "\n",
    "curse_extras = [\n",
    "    \"Fuck this.\", \"Screw this.\", \"This is bullshit.\", \"What the fuck?\",\n",
    "    \"Goddamn it.\", \"This shit again?\", \"Piss off.\", \"Fucking hell.\",\n",
    "    \"Shitty as always.\", \"Damn this crap.\"\n",
    "]\n",
    "\n",
    "# Function to generate a single harsh comment\n",
    "def generate_harsh_comment():\n",
    "    style = random.choice([\"direct\", \"sarcastic\", \"curse\"])\n",
    "    \n",
    "    if style == \"direct\":\n",
    "        return f\"{random.choice(subjects).capitalize()} {random.choice(intensifiers)} {random.choice(negatives)}.\"\n",
    "    elif style == \"sarcastic\":\n",
    "        return f\"{random.choice(sarcasm_starters)} {random.choice(subjects).capitalize()} {random.choice(negatives)}. {random.choice(sarcasm_followups)}\"\n",
    "    else:  # curse\n",
    "        return f\"{random.choice(curse_extras)} {random.choice(subjects).capitalize()} {random.choice(negatives)}.\"\n",
    "\n",
    "# Generate 1,250 harsh comments\n",
    "n_comments = 30000\n",
    "harsh_comments = [generate_harsh_comment() for _ in range(n_comments)]\n",
    "\n",
    "# Ensure variety by adding some unique harsh phrases\n",
    "extra_harsh = [\n",
    "    \"I’d rather die than use this again.\",\n",
    "    \"Whoever made this deserves a slap.\",\n",
    "    \"This is so bad it’s almost impressive.\",\n",
    "    \"What a steaming pile of dog shit.\",\n",
    "    \"I can’t believe I wasted my life on this.\",\n",
    "    \"This is a fucking insult to intelligence.\",\n",
    "    \"Oh, look, another masterpiece of failure.\",\n",
    "    \"This trash isn’t worth the bytes it’s stored on.\",\n",
    "    \"I’m done with this shitshow forever.\",\n",
    "    \"Congrats on screwing up so spectacularly.\"\n",
    "]\n",
    "harsh_comments.extend(extra_harsh[:10])  # Add 10 unique ones\n",
    "harsh_comments = harsh_comments[:n_comments]  # Trim to exactly 1,250 if over\n",
    "\n",
    "# Create DataFrame\n",
    "new_data = pd.DataFrame({\n",
    "    \"Comment\": harsh_comments,\n",
    "    \"Sentiment\": [\"N\"] * n_comments\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"harsh_comments.csv\"\n",
    "new_data.to_csv(output_file, index=False)\n",
    "print(f\"Generated {n_comments} harsh comments and saved to '{output_file}'\")\n",
    "\n",
    "# Optional: Preview first few comments\n",
    "print(\"\\nSample comments:\")\n",
    "print(new_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3231f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 neutral comments and saved to 'neutral_comments.csv'\n",
      "\n",
      "Sample comments:\n",
      "                                            Comment Sentiment\n",
      "0       This app is okay no big deal no complaints.        NU\n",
      "1                            This movie is alright.        NU\n",
      "2  This app is passable no big deal same as always.        NU\n",
      "3                          This product is average.        NU\n",
      "4                                     This is fine.        NU\n",
      "5                            This movie is typical.        NU\n",
      "6                   This is typical kind of anyway.        NU\n",
      "7     This post is typical more or less that’s all.        NU\n",
      "8                      This product sort of is meh.        NU\n",
      "9                                This video is meh.        NU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Base components for generating neutral comments\n",
    "subjects = [\n",
    "    \"this\", \"this app\", \"this update\", \"this movie\", \"this game\", \"this service\",\n",
    "    \"this feature\", \"this site\", \"this thing\", \"this product\", \"this platform\",\n",
    "    \"this post\", \"this video\", \"this event\", \"this weather\"\n",
    "]\n",
    "\n",
    "neutral_descriptors = [\n",
    "    \"is okay\", \"is fine\", \"is alright\", \"seems decent\", \"works well enough\",\n",
    "    \"does the job\", \"is average\", \"is nothing special\", \"is typical\",\n",
    "    \"is standard\", \"is passable\", \"is what it is\", \"is meh\", \"is so-so\",\n",
    "    \"feels normal\"\n",
    "]\n",
    "\n",
    "neutral_modifiers = [\n",
    "    \"I guess\", \"for now\", \"at least\", \"kind of\", \"sort of\", \"in a way\",\n",
    "    \"more or less\", \"pretty much\", \"as expected\", \"not bad but not great\",\n",
    "    \"could be worse\", \"no big deal\", \"just there\", \"fairly\"\n",
    "]\n",
    "\n",
    "neutral_endings = [\n",
    "    \".\", \" I suppose.\", \" whatever.\", \" that’s all.\", \" no complaints.\",\n",
    "    \" it’s fine.\", \" oh well.\", \" nothing to say.\", \" same as always.\",\n",
    "    \" can’t tell.\", \" doesn’t matter.\", \" anyway.\", \" if that matters.\"\n",
    "]\n",
    "\n",
    "# Function to generate a single neutral comment\n",
    "def generate_neutral_comment():\n",
    "    style = random.choice([\"simple\", \"modified\", \"longer\"])\n",
    "    \n",
    "    if style == \"simple\":\n",
    "        return f\"{random.choice(subjects).capitalize()} {random.choice(neutral_descriptors)}.\"\n",
    "    elif style == \"modified\":\n",
    "        return f\"{random.choice(subjects).capitalize()} {random.choice(neutral_modifiers)} {random.choice(neutral_descriptors)}.\"\n",
    "    else:  # longer\n",
    "        return f\"{random.choice(subjects).capitalize()} {random.choice(neutral_descriptors)} {random.choice(neutral_modifiers)}{random.choice(neutral_endings)}\"\n",
    "\n",
    "# Generate 3000 neutral comments\n",
    "n_comments = 10000\n",
    "neutral_comments = [generate_neutral_comment() for _ in range(n_comments)]\n",
    "\n",
    "# Add some hand-crafted neutral comments for variety\n",
    "extra_neutral = [\n",
    "    \"It’s just another day on this platform.\",\n",
    "    \"This is neither here nor there.\",\n",
    "    \"I don’t have strong feelings about this.\",\n",
    "    \"This update is okay, nothing to write home about.\",\n",
    "    \"It works, but I’m not impressed or upset.\",\n",
    "    \"This movie was fine, I guess I’d watch it again.\",\n",
    "    \"Not sure what to think of this, it’s just there.\",\n",
    "    \"This feature exists, that’s about it.\",\n",
    "    \"I’ve seen worse, I’ve seen better.\",\n",
    "    \"This thing is alright, no real opinion.\"\n",
    "]\n",
    "neutral_comments.extend(extra_neutral[:10])  # Add 10 unique ones\n",
    "neutral_comments = neutral_comments[:n_comments]  # Trim to exactly 1,250 if over\n",
    "\n",
    "# Create DataFrame\n",
    "new_data = pd.DataFrame({\n",
    "    \"Comment\": neutral_comments,\n",
    "    \"Sentiment\": [\"NU\"] * n_comments\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"neutral_comments.csv\"\n",
    "new_data.to_csv(output_file, index=False)\n",
    "print(f\"Generated {n_comments} neutral comments and saved to '{output_file}'\")\n",
    "\n",
    "# Preview first few comments\n",
    "print(\"\\nSample comments:\")\n",
    "print(new_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb4c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to 'fb_labeled_balanced.csv' with 174394 rows\n",
      "New Class Distribution:\n",
      "Sentiment\n",
      "P     84438\n",
      "N     60739\n",
      "NU    29217\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load existing dataset (with harsh negatives if already added)\n",
    "df = pd.read_csv(\"fb_labeled_with_emojis.csv\")  # or \"fb_labeled.csv\" if not yet updated\n",
    "\n",
    "# Load generated harsh negative comments\n",
    "harsh_df = pd.read_csv(\"harsh_comments.csv\")\n",
    "\n",
    "# Load generated neutral comments\n",
    "neutral_df = pd.read_csv(\"neutral_comments.csv\")\n",
    "\n",
    "# Combine all\n",
    "df_balanced = pd.concat([df, harsh_df,neutral_df], ignore_index=True)\n",
    "df_balanced.to_csv(\"fb_labeled_balanced.csv\", index=False)\n",
    "print(f\"Balanced dataset saved to 'fb_labeled_balanced.csv' with {len(df_balanced)} rows\")\n",
    "print(\"New Class Distribution:\")\n",
    "print(df_balanced[\"Sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8853994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully extracted code to: face.py\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from nbformat import read as read_notebook\n",
    "import os\n",
    "\n",
    "def extract_code_from_ipynb(input_file, output_file):\n",
    "    try:\n",
    "        # Read the notebook\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            notebook = read_notebook(f, as_version=4)\n",
    "            \n",
    "        # Extract code cells\n",
    "        code_cells = []\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # Join lines and add newline between cells\n",
    "                code = ''.join(cell.source) + '\\n\\n'\n",
    "                code_cells.append(code)\n",
    "                \n",
    "        # Combine all code\n",
    "        full_code = '\\n'.join(code_cells)\n",
    "        \n",
    "        # Write to output file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(full_code)\n",
    "            \n",
    "        print(f\"✅ Successfully extracted code to: {output_file}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "        print(\"Make sure the input file is a valid .ipynb notebook\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prompt user for input file name\n",
    "    input_file = input(\"Enter the path to the input .ipynb file: \").strip()\n",
    "    \n",
    "    # Check if the input file exists\n",
    "    if not os.path.isfile(input_file):\n",
    "        print(f\"❌ Error: The file '{input_file}' does not exist.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Prompt user for output file name (optional)\n",
    "    output_file = input(\"Enter the path to the output .py file (leave blank for default): \").strip()\n",
    "    \n",
    "    # Set default output file name if not provided\n",
    "    if not output_file:\n",
    "        output_file = os.path.splitext(input_file)[0] + '.py'\n",
    "    \n",
    "    # Safeguard 1: Ensure input and output file names are not the same\n",
    "    if os.path.abspath(input_file) == os.path.abspath(output_file):\n",
    "        print(\"❌ Error: Input and output file names cannot be the same to prevent overwriting.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Safeguard 2: Ensure the output file does not have the .ipynb extension\n",
    "    if output_file.endswith('.ipynb'):\n",
    "        print(\"❌ Error: Output file cannot have the .ipynb extension. Please use a different extension (e.g., .py).\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Run the conversion\n",
    "    extract_code_from_ipynb(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7547b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10010 comments with emojis and saved to 'emoji_comments.csv'\n",
      "Class Distribution:\n",
      "Sentiment\n",
      "NU    3337\n",
      "P     3337\n",
      "N     3336\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample comments:\n",
      "                               Comment Sentiment\n",
      "0    This weather really is terrible 😡         N\n",
      "1   This site could be worse is fine 🤔        NU\n",
      "2              This app just is okay 🙃        NU\n",
      "3       This weather always is great 👍         P\n",
      "4     This app completely is useless 😤         N\n",
      "5  This update honestly is the best ❤️         P\n",
      "6  This weather more or less is okay 🧐        NU\n",
      "7        This site super is the best 💖         P\n",
      "8  This weather so works wonderfully 😊         P\n",
      "9        This post fairly is average 🤐        NU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define components for text generation\n",
    "subjects = [\n",
    "    \"this app\", \"this update\", \"this movie\", \"this game\", \"this service\",\n",
    "    \"this feature\", \"this site\", \"this post\", \"this video\", \"this weather\"\n",
    "]\n",
    "\n",
    "# Positive components\n",
    "positive_descriptors = [\n",
    "    \"is awesome\", \"is great\", \"is amazing\", \"is fantastic\", \"is perfect\",\n",
    "    \"works wonderfully\", \"is the best\", \"is lovely\", \"is impressive\", \"is fun\"\n",
    "]\n",
    "positive_modifiers = [\n",
    "    \"really\", \"so\", \"very\", \"totally\", \"absolutely\", \"definitely\",\n",
    "    \"always\", \"super\", \"incredibly\", \"honestly\"\n",
    "]\n",
    "positive_emojis = [\"😊\", \"👍\", \"🎉\", \"❤️\", \"😍\", \"✨\", \"🌟\", \"😎\", \"🥳\", \"💖\"]\n",
    "\n",
    "# Negative components\n",
    "negative_descriptors = [\n",
    "    \"is terrible\", \"is awful\", \"sucks\", \"is garbage\", \"is a mess\",\n",
    "    \"is broken\", \"is useless\", \"is the worst\", \"is crap\", \"is a disaster\"\n",
    "]\n",
    "negative_modifiers = [\n",
    "    \"so\", \"really\", \"totally\", \"utterly\", \"completely\", \"f***ing\",\n",
    "    \"damn\", \"bloody\", \"stupidly\", \"pathetically\"\n",
    "]\n",
    "negative_emojis = [\"😡\", \"👎\", \"😞\", \"💔\", \"😣\", \"🤬\", \"😤\", \"😢\", \"🤮\", \"😠\"]\n",
    "sarcastic_starters = [\n",
    "    \"Oh, great\", \"Wow, brilliant\", \"Nice one\", \"Sure, perfect\", \"Love this\"\n",
    "]\n",
    "\n",
    "# Neutral components\n",
    "neutral_descriptors = [\n",
    "    \"is okay\", \"is fine\", \"is alright\", \"seems decent\", \"works well enough\",\n",
    "    \"is average\", \"is nothing special\", \"is typical\", \"is standard\", \"is meh\"\n",
    "]\n",
    "neutral_modifiers = [\n",
    "    \"kind of\", \"sort of\", \"pretty much\", \"as expected\", \"not bad but not great\",\n",
    "    \"could be worse\", \"no big deal\", \"just\", \"fairly\", \"more or less\"\n",
    "]\n",
    "neutral_emojis = [\"😐\", \"🤷‍♂️\", \"🤔\", \"😶\", \"🙃\", \"😑\", \"🤨\", \"🧐\", \"😕\", \"🤐\"]\n",
    "\n",
    "# Function to generate a single comment with emoji\n",
    "def generate_comment(sentiment):\n",
    "    subject = random.choice(subjects).capitalize()\n",
    "    \n",
    "    if sentiment == \"P\":\n",
    "        text = f\"{subject} {random.choice(positive_modifiers)} {random.choice(positive_descriptors)}\"\n",
    "        emoji = random.choice(positive_emojis)\n",
    "        return f\"{text} {emoji}\", \"P\"\n",
    "    \n",
    "    elif sentiment == \"N\":\n",
    "        style = random.choice([\"direct\", \"sarcastic\"])\n",
    "        if style == \"direct\":\n",
    "            text = f\"{subject} {random.choice(negative_modifiers)} {random.choice(negative_descriptors)}\"\n",
    "        else:\n",
    "            text = f\"{random.choice(sarcastic_starters)}, {subject} {random.choice(negative_descriptors)}\"\n",
    "        emoji = random.choice(negative_emojis)\n",
    "        return f\"{text} {emoji}\", \"N\"\n",
    "    \n",
    "    else:  # NU\n",
    "        text = f\"{subject} {random.choice(neutral_modifiers)} {random.choice(neutral_descriptors)}\"\n",
    "        emoji = random.choice(neutral_emojis)\n",
    "        return f\"{text} {emoji}\", \"NU\"\n",
    "\n",
    "# Generate 5,000 comments (roughly balanced)\n",
    "n_total = 10000\n",
    "n_per_class = n_total // 3  # ~1666 each\n",
    "extra = n_total % 3         # Distribute remainder\n",
    "\n",
    "comments = []\n",
    "sentiments = [\"P\"] * (n_per_class + (1 if extra > 0 else 0)) + \\\n",
    "             [\"N\"] * (n_per_class + (1 if extra > 1 else 0)) + \\\n",
    "             [\"NU\"] * n_per_class\n",
    "\n",
    "random.shuffle(sentiments)  # Randomize order\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    comment, label = generate_comment(sentiment)\n",
    "    comments.append({\"Comment\": comment, \"Sentiment\": label})\n",
    "\n",
    "# Create DataFrame\n",
    "df_emoji = pd.DataFrame(comments)\n",
    "\n",
    "# Add some emoji-only examples (10 per class)\n",
    "emoji_only = [\n",
    "    {\"Comment\": \"😊👍\", \"Sentiment\": \"P\"},\n",
    "    {\"Comment\": \"😍✨\", \"Sentiment\": \"P\"},\n",
    "    {\"Comment\": \"🎉❤️\", \"Sentiment\": \"P\"},\n",
    "    {\"Comment\": \"😡👎\", \"Sentiment\": \"N\"},\n",
    "    {\"Comment\": \"🤬😤\", \"Sentiment\": \"N\"},\n",
    "    {\"Comment\": \"💔😞\", \"Sentiment\": \"N\"},\n",
    "    {\"Comment\": \"😐🤷‍♂️\", \"Sentiment\": \"NU\"},\n",
    "    {\"Comment\": \"🤔😶\", \"Sentiment\": \"NU\"},\n",
    "    {\"Comment\": \"🙃😑\", \"Sentiment\": \"NU\"},\n",
    "    {\"Comment\": \"😕🧐\", \"Sentiment\": \"NU\"}\n",
    "]\n",
    "df_emoji = pd.concat([df_emoji, pd.DataFrame(emoji_only)], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"emoji_comments.csv\"\n",
    "df_emoji.to_csv(output_file, index=False)\n",
    "print(f\"Generated {len(df_emoji)} comments with emojis and saved to '{output_file}'\")\n",
    "\n",
    "# Show class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(df_emoji[\"Sentiment\"].value_counts())\n",
    "\n",
    "# Preview samples\n",
    "print(\"\\nSample comments:\")\n",
    "print(df_emoji.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3867cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to 'fb_labeled_with_emojis.csv' with 134394 rows\n",
      "New Class Distribution:\n",
      "Sentiment\n",
      "P     84438\n",
      "N     30739\n",
      "NU    19217\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load existing dataset\n",
    "df = pd.read_csv(\"fb_labeled_balanced.csv\")\n",
    "\n",
    "# Load emoji data\n",
    "emoji_df = pd.read_csv(\"emoji_comments.csv\")\n",
    "\n",
    "# Combine and save\n",
    "df_with_emojis = pd.concat([df, emoji_df], ignore_index=True)\n",
    "df_with_emojis.to_csv(\"fb_labeled_with_emojis.csv\", index=False)\n",
    "print(f\"Updated dataset saved to 'fb_labeled_with_emojis.csv' with {len(df_with_emojis)} rows\")\n",
    "print(\"New Class Distribution:\")\n",
    "print(df_with_emojis[\"Sentiment\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
